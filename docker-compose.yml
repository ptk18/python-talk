services:
  backend:
    build: ./backend
    platform: linux/amd64
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    networks:
      - python_talk_net
    environment:
      # Disable SentenceTransformer for fast startup
      - DISABLE_SEMANTIC_MATCHING=true
      # Disable Whisper voice model pre-warming (saves 4.5GB RAM)
      # Voice models will lazy-load on first transcription request
      - PREWARM_MODELS=false
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 512M

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    platform: linux/amd64
    ports:
      - "3001:3001"
    volumes:
      - ./frontend:/app/frontend
      - ./packages/shared:/app/packages/shared
      - /app/frontend/node_modules
    depends_on:
      - backend
    networks:
      - python_talk_net
    environment:
      - VITE_API_URL=http://backend:8000

networks:
  python_talk_net:
